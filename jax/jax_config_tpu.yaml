# TPU v5e-8 optimized config (revised)

train_cfg:
  lr: 5.0e-4
  epochs: 60
  batch_size: 128            # vẫn TPU-friendly (divisible by 8)

  warmup_epochs: 5
  warmup_steps: 500
  fusion_alpha_warm: 0.8

  # bật hard negative sớm hơn để tránh plateau lâu ở B
  hard_negative_start_epoch: 25

  use_ranking_loss: true

  # margin schedule: dễ -> khó dần
  ranking_margin: 0.2        # m0 lúc đầu (và trong warmup)
  ranking_margin_B: 0.30     # target margin cuối phase B
  ranking_margin_C: 0.45     # target margin cuối phase C

  # rank_w schedule: tăng mượt
  ranking_weight_phaseB: 0.25   # max cuối phase B (rank_w sẽ ramp 0 -> 0.25)
  ranking_weight_phaseC: 0.60   # max cuối phase C (ramp 0.25 -> 0.60)

  # hard in-batch ranking
  ranking_topk: 5            # lấy mean top-3 hardest negatives (ổn định)

model_cfg:
  input_size: 320
  fusion_alpha: 0.4
  global_hidden_dim: 512
  transformer_layers: 6
  transformer_heads: 8
